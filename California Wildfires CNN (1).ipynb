{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'uci_ml_hackathon_fire_dataset_2012-05-09_2013-01-01_10k_train.hdf5'\n",
    "\n",
    "with h5py.File(DATASET_PATH, 'r') as f:\n",
    "    train_data = {}\n",
    "    for k in list(f):\n",
    "        train_data[k] = f[k][:]\n",
    "        \n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Land Cover\", train_data['land_cover'].shape)\n",
    "print(\"Data point\", train_data['land_cover'][90].shape)\n",
    "print(\"Layer\", train_data['land_cover'][90][0].shape)\n",
    "print(train_data['land_cover'][90][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['land_cover'][0].reshape(17,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Land Cover\", train_data['land_cover'].shape)\n",
    "print(train_data['land_cover'][0][0])\n",
    "print(\"Data point\", train_data['land_cover'][1000].shape)\n",
    "print(\"Layer\", train_data['land_cover'][1000][10].shape)\n",
    "#print(train_data['land_cover'][1000][10])\n",
    "summ = 0\n",
    "for i in range(6, 16):\n",
    "    summ += train_data['land_cover'][1000][i]\n",
    "#print(summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_aspect = pd.DataFrame()\n",
    "# df_canopydensity = pd.DataFrame()\n",
    "# df_canopybaseheight = pd.DataFrame()\n",
    "# df_canopycover = pd.DataFrame()\n",
    "# df_canopyHeight = pd.DataFrame()\n",
    "# df_elevation = pd.DataFrame()\n",
    "# df_slope = pd.DataFrame()\n",
    "# df_observed_48 = pd.DataFrame()\n",
    "# df_observed_36 = pd.DataFrame()\n",
    "# df_observed_24 = pd.DataFrame()\n",
    "# df_observed_12 = pd.DataFrame()\n",
    "# df_observed_0 = pd.DataFrame()\n",
    "# df_target_12 = pd.DataFrame()\n",
    "# df_datetime = pd.DataFrame()\n",
    "# df_latitude = pd.DataFrame()\n",
    "# df_longitude = pd.DataFrame()\n",
    "\n",
    "aspect = list()\n",
    "canopydensity = list()\n",
    "canopybaseheight = list()\n",
    "canopycover = list()\n",
    "canopyHeight = list()\n",
    "elevation = list()\n",
    "slope = list()\n",
    "observed_48 = list()\n",
    "observed_36 = list()\n",
    "observed_24 = list()\n",
    "observed_12 = list()\n",
    "observed_0 = list()\n",
    "target_12 = list()\n",
    "datetime = list()\n",
    "latitude = list()\n",
    "longitude = list()\n",
    "\n",
    "for i in range(10000):\n",
    "#     aspect.append(train_data['land_cover'][i][0])\n",
    "#     canopydensity.append(train_data['land_cover'][i][1])\n",
    "#     canopybaseheight.append(train_data['land_cover'][i][2])\n",
    "#     canopycover.append(train_data['land_cover'][i][3])\n",
    "#     canopyHeight.append(train_data['land_cover'][i][4])\n",
    "#     elevation.append(train_data['land_cover'][i][5])\n",
    "#     slope.append(train_data['land_cover'][i][16])\n",
    "    observed_48.append(train_data['observed'][i][4])\n",
    "    observed_36.append(train_data['observed'][i][3])\n",
    "    observed_24.append(train_data['observed'][i][2])\n",
    "    observed_12.append(train_data['observed'][i][1])\n",
    "    observed_0.append(train_data['observed'][i][0])\n",
    "    #datetime.append(train_data['land_cover'][i][2])\n",
    "\n",
    "\n",
    "#aspect, canopydensity, canopybaseheight, canopycover, canopyHeight, elevation, slope, \n",
    "X = np.stack((observed_48, observed_36, observed_24, observed_12, observed_0))\n",
    "X = np.rollaxis(X, 1, 0)  \n",
    "print(X.shape)\n",
    "\n",
    "X[np.isnan(X)] = np.median(X[~np.isnan(X)])\n",
    "#np.all(np.isfinite(X_train))\n",
    "#print(aspect[0])\n",
    "#print(canopydensity[0])\n",
    "\n",
    "\n",
    "#     df_observed_48 = df_observed_48.append({'Observed-48':np.array(train_data['observed'][i].reshape(5,-1)[4])}, ignore_index=True)\n",
    "#     df_observed_36 = df_observed_36.append({'Observed-36':np.array(train_data['observed'][i].reshape(5,-1)[3])}, ignore_index=True)\n",
    "#     df_observed_24 = df_observed_24.append({'Observed-24':np.array(train_data['observed'][i].reshape(5,-1)[2])}, ignore_index=True)\n",
    "#     df_observed_12 = df_observed_12.append({'Observed-12':np.array(train_data['observed'][i].reshape(5,-1)[1])}, ignore_index=True)\n",
    "#     df_observed_0 = df_observed_0.append({'Observed-0':np.array(train_data['observed'][i].reshape(5,-1)[0])}, ignore_index=True)\n",
    "\n",
    "#print(aspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data['target'][1170][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_datetime, df_latitude, df_longitude, \n",
    "# data_frames = [df_aspect, df_canopydensity, df_canopybaseheight, df_canopycover, df_canopyHeight, df_elevation, df_slope, df_observed_48, df_observed_36, df_observed_24, df_observed_12, df_observed_0]\n",
    "# train = reduce(lambda  left,right: pd.merge(left, right, how='left', left_index=True, right_index=True), data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X.head(10000))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_12 = list()\n",
    "for i in range(10000):\n",
    "    df_target_12.append(train_data['target'][i][0])\n",
    "\n",
    "print(len(df_target_12))\n",
    "print(np.asarray(df_target_12).shape)\n",
    "#nsamples, nx, ny = np.asarray(df_target_12).shape\n",
    "#.reshape((nsamples,nx*ny))\n",
    "Y_train = np.asarray(df_target_12)\n",
    "#Y_train = Y_train.reshape([-1,1, 30, 30])\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_train, test_size = 0.1, random_state = 1)\n",
    "#x_train, x_cv, y_train, y_cv = train_test_split(x_train, y_train, test_size=0.2)\n",
    "print(x_train.shape, y_train.shape)\n",
    "#print(x_cv.shape, y_cv.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten, Dropout\n",
    "from keras.layers import concatenate\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.optimizers import adadelta,RMSprop,SGD,Adam\n",
    "from keras.layers.convolutional import MaxPooling2D, AveragePooling2D\n",
    "import tensorflow as tf\n",
    "\n",
    "model = Sequential()\n",
    "model.add(AveragePooling2D())\n",
    "model.add(Conv2D(filters=4, kernel_size=(3,3), activation='sigmoid', data_format='channels_first'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(Conv2D(filters=4, kernel_size=3, activation='relu', input_shape=(5,30,30), data_format='channels_first'))\n",
    "#model.add(MaxPooling2D(pool_size=2))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Conv1D(filters=16, kernel_size=3, activation='relu'))\n",
    "model.compile(optimizer=RMSprop(), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size= 16, epochs=1)\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(Flatten())\n",
    "#model.add(Dense(900, activation='softmax'))\n",
    "\n",
    "#yhat = model.predict(x_test, verbose=0)\n",
    "print(model.evaluate(x_test, y_test))\n",
    "#print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(x_test)\n",
    "print(y_test[300])\n",
    "print(yhat[300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear_svc = LinearSVC()\n",
    "# linear_svc.fit(x_train, y_train)\n",
    "# y_pred = linear_svc.predict(x_test)\n",
    "# acc_linear_svc = round(accuracy_score(y_pred, y_test) * 100, 2)\n",
    "# acc_linear_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha = [100,200,500,1000,2000]\n",
    "# max_depth = [5, 10]\n",
    "# cv_log_accuracy_array = []\n",
    "# for i in alpha:\n",
    "#     for j in max_depth:\n",
    "#         print(\"for n_estimators =\", i,\"and max depth = \", j)\n",
    "#         clf = RandomForestClassifier(n_estimators=i, criterion='gini', max_depth=j, random_state=42, n_jobs=-1)\n",
    "#         clf.fit(x_train, y_train)\n",
    "#         y_cv_pred = clf.predict(x_cv)\n",
    "#         acc_randomforest = round(accuracy_score(y_cv_pred, y_cv) * 100, 2)\n",
    "#         cv_log_accuracy_array.append(acc_randomforest)\n",
    "#         print(\"Accuracy: \",acc_randomforest)\n",
    "\n",
    "        \n",
    "\n",
    "# # randomforest = RandomForestClassifier()\n",
    "# # randomforest.fit(x_train, y_train)\n",
    "# # y_pred = randomforest.predict(x_test)\n",
    "# # acc_randomforest = round(accuracy_score(y_pred, y_test) * 100, 2)\n",
    "# # print(acc_randomforest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_alpha = np.argmin(cv_log_accuracy_array)\n",
    "# clf = RandomForestClassifier(n_estimators=alpha[int(best_alpha/2)], criterion='gini', max_depth=max_depth[int(best_alpha%2)], random_state=42, n_jobs=-1)\n",
    "# clf.fit(x_train, y_train)\n",
    "\n",
    "# predict_y = clf.predict(x_train)\n",
    "# print('For values of best estimator = ', alpha[int(best_alpha/2)], \"The train log loss is:\",log_loss(y_train, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "# predict_y = clf.predict(x_cv)\n",
    "# print('For values of best estimator = ', alpha[int(best_alpha/2)], \"The cross validation log loss is:\",log_loss(y_cv, predict_y, labels=clf.classes_, eps=1e-15))\n",
    "# predict_y = clf.predict(x_test)\n",
    "# print('For values of best estimator = ', alpha[int(best_alpha/2)], \"The test log loss is:\",log_loss(y_test, predict_y, labels=clf.classes_, eps=1e-15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
